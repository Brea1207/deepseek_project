# LLM è”ç½‘æœç´¢æ’ä»¶ (LLM Web Search Plugin)

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.7%2B-blue" alt="Python 3.7+">
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License: MIT">
  <img src="https://img.shields.io/badge/Version-1.0.0-orange" alt="Version: 1.0.0">
</div>

## ğŸ“– ç®€ä»‹ (Introduction)

è¿™ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªä¸ºæœ¬åœ°éƒ¨ç½²çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›è”ç½‘æœç´¢åŠŸèƒ½çš„æ’ä»¶ã€‚ç”±äºæœ¬åœ°éƒ¨ç½²çš„å¤§æ¨¡å‹é€šå¸¸æ— æ³•ç›´æ¥è”ç½‘æœç´¢ï¼Œè¿™ä¸ªæ’ä»¶å¯ä»¥å¸®åŠ©æ¨¡å‹è·å–æœ€æ–°çš„äº’è”ç½‘ä¿¡æ¯ï¼Œä»è€Œæä¾›æ›´å‡†ç¡®å’ŒåŠæ—¶çš„å›ç­”ã€‚

This project is a plugin that provides web search capabilities for locally deployed Large Language Models (LLMs). Since locally deployed LLMs typically cannot directly search the internet, this plugin helps models obtain the latest internet information, enabling more accurate and timely responses.

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹ (Features)

- ğŸ” æ”¯æŒå¤šç§æœç´¢å¼•æ“ï¼ˆç›®å‰æ”¯æŒ Googleã€Bing å’Œç™¾åº¦ï¼‰
- ğŸ“ å¯ä»¥è·å–æœç´¢ç»“æœæ‘˜è¦
- ğŸ“„ å¯ä»¥æŠ“å–ç½‘é¡µè¯¦ç»†å†…å®¹
- ğŸ¤– è‡ªåŠ¨æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºé€‚åˆ LLM å¤„ç†çš„æç¤ºè¯
- ğŸ”Œ æä¾›ç®€å•çš„ API æ¥å£ï¼Œæ˜“äºä¸å„ç§ LLM é›†æˆ
- ğŸ“š åŒ…å«ç¤ºä¾‹å®¢æˆ·ç«¯ä»£ç ï¼Œå±•ç¤ºå¦‚ä½•ä¸æœ¬åœ° LLM é›†æˆ
- ğŸ‡¨ğŸ‡³ é’ˆå¯¹ä¸­æ–‡æœç´¢ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨ç™¾åº¦æœç´¢å¼•æ“
- â° æ”¯æŒè·å–å®æ—¶æ—¶é—´ä¿¡æ¯
- ğŸ› ï¸ æä¾›å¯é…ç½®çš„ Web ç•Œé¢ï¼Œæ–¹ä¾¿è°ƒæ•´å„é¡¹å‚æ•°

## ğŸ”§ ç³»ç»Ÿè¦æ±‚ (System Requirements)

- Python 3.7+
- ç½‘ç»œè¿æ¥
- æœ¬åœ°éƒ¨ç½²çš„ LLMï¼ˆæ¨èä½¿ç”¨ Ollamaã€llama.cpp ç­‰ï¼‰

## ğŸ“¦ å®‰è£…æ­¥éª¤ (Installation)

1. å…‹éš†æˆ–ä¸‹è½½æœ¬ä»“åº“

```bash
```

2. å®‰è£…ä¾èµ–åŒ…

```bash
pip install -r requirements.txt
```

3. åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

```
DEBUG=True
PORT=5005
SEARCH_ENGINE=google  # å¯é€‰å€¼: google, bing, baidu
```

## ğŸš€ ä½¿ç”¨æ–¹æ³• (Usage)

### å¯åŠ¨æœç´¢ API æœåŠ¡

```bash
python run_server.py
```

æœåŠ¡å°†åœ¨ http://localhost:5005 å¯åŠ¨ï¼ˆé™¤éåœ¨ .env æ–‡ä»¶ä¸­æŒ‡å®šäº†å…¶ä»–ç«¯å£ï¼‰ã€‚

ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šæœç´¢å¼•æ“ï¼š

```bash
SEARCH_ENGINE=baidu python run_server.py
```

### è®¿é—® Web ç•Œé¢

å¯åŠ¨æœåŠ¡åï¼Œå¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®ä»¥ä¸‹é¡µé¢ï¼š

- ä¸»é¡µ: http://localhost:5005/
- LLM äº¤äº’é¡µé¢: http://localhost:5005/llm
- é…ç½®é¡µé¢: http://localhost:5005/config

### API ç«¯ç‚¹

#### POST /search

æ‰§è¡Œç½‘ç»œæœç´¢å¹¶è¿”å›æ ¼å¼åŒ–çš„ç»“æœã€‚

è¯·æ±‚ç¤ºä¾‹ï¼š

```json
{
    "query": "ä½ çš„æœç´¢æŸ¥è¯¢",
    "num_results": 5,
    "fetch_content": false,
    "search_engine": "baidu",
    "llm_model": "deepseek-r1:1.5b",
    "temperature": 0.7,
    "max_tokens": 2048
}
```

å‚æ•°è¯´æ˜ï¼š
- `query`: æœç´¢æŸ¥è¯¢ï¼ˆå¿…éœ€ï¼‰
- `num_results`: è¿”å›ç»“æœæ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º 5ï¼‰
- `fetch_content`: æ˜¯å¦è·å–è¯¦ç»†ç½‘é¡µå†…å®¹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º falseï¼‰
- `search_engine`: ä½¿ç”¨çš„æœç´¢å¼•æ“ï¼Œ"google"ã€"bing" æˆ– "baidu"ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º "google"ï¼‰
- `llm_model`: ä½¿ç”¨çš„ LLM æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
- `temperature`: ç”Ÿæˆæ¸©åº¦ï¼ˆå¯é€‰ï¼‰
- `max_tokens`: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆå¯é€‰ï¼‰

å“åº”ç¤ºä¾‹ï¼š

```json
{
    "query": "ä½ çš„æœç´¢æŸ¥è¯¢",
    "search_results": [
        {
            "title": "ç»“æœæ ‡é¢˜",
            "link": "https://example.com",
            "snippet": "ç»“æœæ‘˜è¦..."
        },
        ...
    ],
    "detailed_content": {
        "https://example.com": "ç½‘é¡µå†…å®¹..."
    },
    "formatted_response": "æ ¼å¼åŒ–åçš„æç¤ºè¯ï¼Œå¯ç›´æ¥å‘é€ç»™ LLM",
    "llm_config": {
        "model": "deepseek-r1:1.5b",
        "temperature": 0.7,
        "max_tokens": 2048
    }
}
```

#### GET /current_time

è·å–å½“å‰æ—¶é—´ä¿¡æ¯ã€‚

å“åº”ç¤ºä¾‹ï¼š

```json
{
    "time": "2025-03-11 17:00:55",
    "timezone": "Asia/Shanghai",
    "source": "system"
}
```

## ğŸ”„ ä¸æœ¬åœ° LLM é›†æˆ (Integration with Local LLMs)

`llm_client_example.py` æ–‡ä»¶æä¾›äº†ä¸€ä¸ªç¤ºä¾‹å®¢æˆ·ç«¯ï¼Œå·²ç»å†…ç½®æ”¯æŒ Ollamaã€llama.cpp ç­‰å¤šç§æœ¬åœ°æ¨¡å‹ã€‚æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œè¿è¡Œå®¢æˆ·ç«¯ï¼Œä¹Ÿå¯ä»¥åœ¨è‡ªå·±çš„ä»£ç ä¸­å¯¼å…¥å¹¶ä½¿ç”¨å®¢æˆ·ç«¯ç±»ã€‚

### å‘½ä»¤è¡Œè¿è¡Œç¤ºä¾‹

```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼ˆOllama å’Œ llama3 æ¨¡å‹ï¼‰
python llm_client_example.py

# æŒ‡å®šä¸åŒçš„æ¨¡å‹
python llm_client_example.py --model-name qwen:7b

# æŒ‡å®šä¸åŒçš„æœç´¢å¼•æ“
python llm_client_example.py --search-engine baidu

# æŒ‡å®šä¸åŒçš„æ¸©åº¦å‚æ•°
python llm_client_example.py --temperature 0.5
```

### åœ¨è‡ªå·±çš„ä»£ç ä¸­ä½¿ç”¨ç¤ºä¾‹

```python
from llm_client_example import LLMWebSearchClient

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆé»˜è®¤ä½¿ç”¨ Ollama å’Œ llama3 æ¨¡å‹ï¼‰
client = LLMWebSearchClient()

# æˆ–è€…æŒ‡å®šä¸åŒçš„æ¨¡å‹
# client = LLMWebSearchClient(llm_type="ollama", model_name="qwen:7b")

# ä½¿ç”¨ç½‘ç»œæœç´¢å›ç­”é—®é¢˜
result = client.answer_with_web_search("æœ€æ–°çš„ AI æŠ€æœ¯è¿›å±•æ˜¯ä»€ä¹ˆï¼Ÿ")

# æ‰“å° LLM çš„å›ç­”
print(result["llm_response"])
```

## ğŸ§ª æµ‹è¯•å·¥å…· (Testing Tools)

é¡¹ç›®ä¸­åŒ…å«ä¸€ä¸ªç»¼åˆæµ‹è¯•å·¥å…· `test_utils.py`ï¼Œæä¾›äº†å¤šç§æµ‹è¯•åŠŸèƒ½ï¼š

1. æµ‹è¯•æœç´¢å¼•æ“çš„æœç´¢ç»“æœ
2. æµ‹è¯•LLMå¯¹æœç´¢ç»“æœçš„åˆ©ç”¨æƒ…å†µ
3. æ¯”è¾ƒä¸åŒæœç´¢å¼•æ“çš„ç»“æœå·®å¼‚

### ä½¿ç”¨æ–¹æ³•

```bash
# æµ‹è¯•æœç´¢å¼•æ“
python test_utils.py --mode search --query "é‡å­è®¡ç®—" --search-engine baidu

# æµ‹è¯•LLMå“åº”
python test_utils.py --mode llm --query "äººå·¥æ™ºèƒ½åº”ç”¨" --model "qwen:7b" --temperature 0.5

# æ¯”è¾ƒæœç´¢å¼•æ“
python test_utils.py --mode compare --query "æ·±åº¦å­¦ä¹ æ¡†æ¶å¯¹æ¯”"
```

### å‚æ•°è¯´æ˜

- `--mode`: æµ‹è¯•æ¨¡å¼ï¼Œå¯é€‰å€¼ä¸º "search"(æµ‹è¯•æœç´¢å¼•æ“)ã€"llm"(æµ‹è¯•LLMå“åº”)ã€"compare"(æ¯”è¾ƒæœç´¢å¼•æ“)
- `--query`: è¦æµ‹è¯•çš„æŸ¥è¯¢ï¼ˆå¦‚æœä¸æä¾›ï¼Œå°†ä½¿ç”¨é»˜è®¤æŸ¥è¯¢"é‡å­è®¡ç®—æœ€æ–°è¿›å±•"ï¼‰
- `--verbose`: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®Œæ•´æç¤ºè¯
- `--search-engine`: ä½¿ç”¨çš„æœç´¢å¼•æ“ï¼Œå¯é€‰å€¼ä¸º "google"ã€"bing" æˆ– "baidu"ï¼ˆé»˜è®¤ä¸º "baidu"ï¼‰
- `--engines`: æ¯”è¾ƒæ¨¡å¼ä¸‹è¦æ¯”è¾ƒçš„æœç´¢å¼•æ“åˆ—è¡¨ï¼ˆé»˜è®¤ä¸º "google bing baidu"ï¼‰
- `--mock`: ä½¿ç”¨æ¨¡æ‹Ÿæœç´¢æ•°æ®ï¼Œä¸è¿›è¡Œå®é™…æœç´¢
- `--model`: æŒ‡å®šä½¿ç”¨çš„ LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä¸º "deepseek-r1:1.5b"ï¼‰
- `--api-url`: æŒ‡å®šæœç´¢ API çš„ URLï¼ˆé»˜è®¤ä¸º "http://localhost:5005/search"ï¼‰
- `--temperature`: LLM ç”Ÿæˆçš„æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ä¸º 0.7ï¼‰
- `--num-results`: æœç´¢ç»“æœæ•°é‡ï¼ˆé»˜è®¤ä¸º 5ï¼‰
- `--fetch-content`: è·å–è¯¦ç»†ç½‘é¡µå†…å®¹

## ğŸŒ æ”¯æŒçš„ LLM æ¨¡å‹ (Supported LLM Models)

æœ€æ–°ç‰ˆæœ¬çš„å®¢æˆ·ç«¯å·²ç»å†…ç½®æ”¯æŒå¤šç§æœ¬åœ°æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š

### Ollama æ”¯æŒçš„æ¨¡å‹

- llama3 (æ¨è)
- deepseek-r1:1.5b / 7b / 671b
- qwen:7b / 14b / 72b
- yi:34b
- gemma:7b / 2b
- mistral:7b
- mixtral:8x7b
- ...ä»¥åŠå…¶ä»– Ollama æ”¯æŒçš„æ¨¡å‹

### å¦‚ä½•ä½¿ç”¨ Ollama

Ollama æ˜¯ä¸€ä¸ªæµè¡Œçš„æœ¬åœ°æ¨¡å‹éƒ¨ç½²å·¥å…·ï¼Œå¯ä»¥è½»æ¾è¿è¡Œå„ç§å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ’ä»¶é»˜è®¤æ”¯æŒ Ollamaã€‚

1. é¦–å…ˆï¼Œç¡®ä¿æ‚¨å·²ç»å®‰è£…äº† Ollamaï¼Œå®‰è£…æŒ‡å—å¯ä»¥åœ¨ [Ollama å®˜æ–¹ç½‘ç«™](https://ollama.ai) æ‰¾åˆ°ã€‚

2. ä¸‹è½½æ‚¨æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¾‹å¦‚ï¼š

```bash
ollama pull llama3
# æˆ–è€…å…¶ä»–æ¨¡å‹ï¼Œå¦‚
# ollama pull qwen:7b
# ollama pull gemma:7b
```

3. ä½¿ç”¨æˆ‘ä»¬çš„å®¢æˆ·ç«¯è¿æ¥åˆ° Ollamaï¼š

```bash
python llm_client_example.py --llm-type ollama --model-name llama3
```

## âš™ï¸ é…ç½®é€‰é¡¹ (Configuration Options)

é€šè¿‡è®¿é—®é…ç½®é¡µé¢ (http://localhost:5005/config)ï¼Œæ‚¨å¯ä»¥è°ƒæ•´ä»¥ä¸‹é…ç½®é€‰é¡¹ï¼š

### æœç´¢è®¾ç½®
- é»˜è®¤æœç´¢å¼•æ“ (Google, Bing, Baidu)
- é»˜è®¤ç»“æœæ•°é‡
- æ˜¯å¦é»˜è®¤è·å–è¯¦ç»†å†…å®¹
- æœ€å¤§å†…å®¹é•¿åº¦

### æ—¶é—´è·å–è®¾ç½®
- é»˜è®¤æ—¶åŒº
- æ—¶é—´æº URL

### LLM æ¨¡å‹è®¾ç½®
- é»˜è®¤ LLM æ¨¡å‹
- é»˜è®¤æ¸©åº¦å‚æ•°
- é»˜è®¤æœ€å¤§ token æ•°

### é«˜çº§è®¾ç½®
- User Agent
- æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•

## ğŸ¤ è´¡çŒ® (Contributing)

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ï¼æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å‚ä¸ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºæ‚¨çš„ç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ‚¨çš„æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯ä¸€ä¸ª Pull Request

## ğŸ“„ è®¸å¯è¯ (License)

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“ è”ç³»æ–¹å¼ (Contact)

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ï¼š

- é¡¹ç›®ä¸»é¡µ: [GitHub ä»“åº“](https://github.com/yourusername/llm-web-search-plugin)
- ç”µå­é‚®ä»¶: 1692775560@qq.com

---

<div align="center">
  <p>Made with â¤ï¸ for LLM enthusiasts</p>
</div>
